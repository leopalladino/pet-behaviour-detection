# MediaPipe Settings
MEDIAPIPE_MODEL_COMPLEXITY=2
CONFIDENCE_THRESHOLD=0.5

# Mixtral Configuration 
MIXTRAL_API_URL=https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-v0.1
HUGGINGFACE_API_TOKEN=your_huggingface_token_here

# Application Settings
MAX_LATENCY_MS=300
DEBUG_MODE=False
LOG_LEVEL=INFO

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
WS_PORT=8001

# Pet Video Dialogue Configuration

# Local LLM Model Configuration
LOCAL_MODEL_PATH=tiny-llama/TinyLlama-1.1B-Chat-v1.0  # Path to local model or HuggingFace model ID
USE_HALF_PRECISION=true  # Use half precision for faster inference

# Output Directory
OUTPUT_DIR=output  # Directory for processed videos 